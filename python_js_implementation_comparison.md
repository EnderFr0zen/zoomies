# Python èˆ‡ JavaScript çœ¼å‹•è¿½è¹¤å¯¦ç¾å°æ¯”

## âœ… å·²å¯¦ç¾çš„ 100% åŒ¹é…åŠŸèƒ½

### 1. ç²¾ç¢ºçš„å¸¸æ•¸å®šç¾©
```python
# Python ç‰ˆæœ¬
LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
LEFT_EYE_CENTER = 468
RIGHT_EYE_CENTER = 473
LEFT_EYE_INNER = 133
LEFT_EYE_OUTER = 33
RIGHT_EYE_INNER = 362
RIGHT_EYE_OUTER = 263
```

```javascript
// JavaScript ç‰ˆæœ¬ - å®Œå…¨åŒ¹é…
const LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246]
const RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]
const LEFT_EYE_CENTER = 468
const RIGHT_EYE_CENTER = 473
const LEFT_EYE_INNER = 133
const LEFT_EYE_OUTER = 33
const RIGHT_EYE_INNER = 362
const RIGHT_EYE_OUTER = 263
```

### 2. è¦–ç·šæ¯”ä¾‹è¨ˆç®—ç®—æ³•
```python
# Python ç‰ˆæœ¬
def calculate_gaze_ratio(eye_landmarks, p1_idx, p2_idx, center_idx):
    p1 = np.array(eye_landmarks[p1_idx])
    p2 = np.array(eye_landmarks[p2_idx])
    center = np.array(eye_landmarks[center_idx])
    
    left_point = p1 if p1[0] < p2[0] else p2
    right_point = p2 if p1[0] < p2[0] else p1
    
    eye_width = right_point[0] - left_point[0]
    if eye_width == 0:
        return 0.5
    
    center_horizontal_pos = center[0] - left_point[0]
    ratio = center_horizontal_pos / eye_width
    
    return np.clip(ratio, 0.0, 1.0)
```

```javascript
// JavaScript ç‰ˆæœ¬ - å®Œå…¨åŒ¹é…
const calculateGazeRatio = useCallback((eyeLandmarks, p1Idx, p2Idx, centerIdx) => {
    const p1 = [eyeLandmarks[p1Idx].x, eyeLandmarks[p1Idx].y]
    const p2 = [eyeLandmarks[p2Idx].x, eyeLandmarks[p2Idx].y]
    const center = [eyeLandmarks[centerIdx].x, eyeLandmarks[centerIdx].y]
    
    const leftPoint = p1[0] < p2[0] ? p1 : p2
    const rightPoint = p1[0] < p2[0] ? p2 : p1
    
    const eyeWidth = rightPoint[0] - leftPoint[0]
    if (eyeWidth === 0) {
        return 0.5
    }

    const centerHorizontalPos = center[0] - leftPoint[0]
    const ratio = centerHorizontalPos / eyeWidth
    
    return Math.max(0.0, Math.min(1.0, ratio))
}, [])
```

### 3. çœ¼ç›ç¸±æ©«æ¯” (EAR) è¨ˆç®—
```python
# Python ç‰ˆæœ¬
def calculate_eye_aspect_ratio(eye_landmarks):
    top_landmarks = [1, 2]
    bottom_landmarks = [4, 5]
    horizontal_landmarks = [0, 3]
    
    vertical_distances = []
    for top_idx in top_landmarks:
        for bottom_idx in bottom_landmarks:
            if top_idx < len(eye_landmarks) and bottom_idx < len(eye_landmarks):
                vertical_dist = np.linalg.norm(
                    np.array(eye_landmarks[top_idx]) - np.array(eye_landmarks[bottom_idx])
                )
                vertical_distances.append(vertical_dist)
    
    horizontal_dist = 0
    if len(horizontal_landmarks) >= 2:
        horizontal_dist = np.linalg.norm(
            np.array(eye_landmarks[horizontal_landmarks[0]]) - 
            np.array(eye_landmarks[horizontal_landmarks[1]])
        )
    
    if horizontal_dist == 0:
        return 0.3
    
    avg_vertical = np.mean(vertical_distances) if vertical_distances else 0
    ear = avg_vertical / horizontal_dist
    
    return ear
```

```javascript
// JavaScript ç‰ˆæœ¬ - å®Œå…¨åŒ¹é…
const calculateEAR = useCallback((eyeLandmarks) => {
    const topLandmarks = [1, 2]
    const bottomLandmarks = [4, 5]
    const horizontalLandmarks = [0, 3]
    
    const verticalDistances = []
    for (const topIdx of topLandmarks) {
        for (const bottomIdx of bottomLandmarks) {
            if (topIdx < eyeLandmarks.length && bottomIdx < eyeLandmarks.length) {
                const verticalDist = Math.sqrt(
                    Math.pow(eyeLandmarks[topIdx].x - eyeLandmarks[bottomIdx].x, 2) +
                    Math.pow(eyeLandmarks[topIdx].y - eyeLandmarks[bottomIdx].y, 2)
                )
                verticalDistances.push(verticalDist)
            }
        }
    }
    
    let horizontalDist = 0
    if (horizontalLandmarks.length >= 2) {
        horizontalDist = Math.sqrt(
            Math.pow(eyeLandmarks[horizontalLandmarks[0]].x - eyeLandmarks[horizontalLandmarks[1]].x, 2) +
            Math.pow(eyeLandmarks[horizontalLandmarks[0]].y - eyeLandmarks[horizontalLandmarks[1]].y, 2)
        )
    }
    
    if (horizontalDist === 0) {
        return 0.3
    }
    
    const avgVertical = verticalDistances.length > 0 ? 
        verticalDistances.reduce((a, b) => a + b, 0) / verticalDistances.length : 0
    const ear = avgVertical / horizontalDist
    
    return ear
}, [])
```

### 4. æ³¨æ„åŠ›ç‹€æ…‹æª¢æ¸¬
```python
# Python ç‰ˆæœ¬
def detect_attention_status(face_landmarks):
    if not face_landmarks or len(face_landmarks) == 0:
        return {"looking_at_screen": False, "confidence": 0.0, "gaze_direction": "no_face_detected"}
    
    landmarks = face_landmarks[0]
    all_landmarks = [(lm.x, lm.y) for lm in landmarks]
    
    left_eye_landmarks = [all_landmarks[i] for i in LEFT_EYE_INDICES]
    right_eye_landmarks = [all_landmarks[i] for i in RIGHT_EYE_INDICES]
    
    left_ear = calculate_eye_aspect_ratio(left_eye_landmarks)
    right_ear = calculate_eye_aspect_ratio(right_eye_landmarks)
    avg_ear = (left_ear + right_ear) / 2.0
    
    eyes_open = avg_ear > 0.20
    
    if not eyes_open:
        return {
            "looking_at_screen": False, 
            "confidence": 0.0, 
            "gaze_direction": "eyes_closed",
            "ear": avg_ear,
            "student_status": "Student not looking at the screen"
        }
    
    left_gaze_ratio = calculate_gaze_ratio(
        all_landmarks, LEFT_EYE_INNER, LEFT_EYE_OUTER, LEFT_EYE_CENTER
    )
    right_gaze_ratio = calculate_gaze_ratio(
        all_landmarks, RIGHT_EYE_INNER, RIGHT_EYE_OUTER, RIGHT_EYE_CENTER
    )
    
    avg_gaze_ratio = (left_gaze_ratio + right_gaze_ratio) / 2.0
    
    if avg_gaze_ratio < 0.4:
        gaze_direction = "looking_left"
    elif avg_gaze_ratio > 0.6:
        gaze_direction = "looking_right"
    else:
        gaze_direction = "looking_straight"
    
    center_distance = abs(avg_gaze_ratio - 0.5)
    confidence = max(0, 1 - center_distance * 2)
    
    looking_at_screen = confidence >= 0.90
    
    student_status = "Student looking at the screen" if looking_at_screen else "Student not looking at the screen"
    
    return {
        "looking_at_screen": looking_at_screen,
        "confidence": confidence,
        "gaze_direction": gaze_direction,
        "gaze_ratio": avg_gaze_ratio,
        "ear": avg_ear,
        "eyes_open": eyes_open,
        "student_status": student_status
    }
```

```javascript
// JavaScript ç‰ˆæœ¬ - å®Œå…¨åŒ¹é…
const detectAttentionStatus = useCallback((faceLandmarks) => {
    if (!faceLandmarks || faceLandmarks.length === 0) {
        return {
            looking_at_screen: false,
            confidence: 0.0,
            gaze_direction: "no_face_detected",
            gaze_ratio: 0.5,
            ear: 0,
            eyes_open: false,
            student_status: "Student not looking at the screen"
        }
    }

    const landmarks = faceLandmarks[0]
    const allLandmarks = landmarks.map((lm) => ({ x: lm.x, y: lm.y }))
    
    const leftEyeLandmarks = LEFT_EYE_INDICES.map(idx => allLandmarks[idx]).filter(Boolean)
    const rightEyeLandmarks = RIGHT_EYE_INDICES.map(idx => allLandmarks[idx]).filter(Boolean)
    
    const leftEAR = calculateEAR(leftEyeLandmarks)
    const rightEAR = calculateEAR(rightEyeLandmarks)
    const avgEAR = (leftEAR + rightEAR) / 2.0
    
    const eyesOpen = avgEAR > 0.20
    
    if (!eyesOpen) {
        return {
            looking_at_screen: false,
            confidence: 0.0,
            gaze_direction: "eyes_closed",
            ear: avgEAR,
            eyes_open: false,
            student_status: "Student not looking at the screen"
        }
    }
    
    const leftGazeRatio = calculateGazeRatio(
        allLandmarks, LEFT_EYE_INNER, LEFT_EYE_OUTER, LEFT_EYE_CENTER
    )
    const rightGazeRatio = calculateGazeRatio(
        allLandmarks, RIGHT_EYE_INNER, RIGHT_EYE_OUTER, RIGHT_EYE_CENTER
    )
    
    const avgGazeRatio = (leftGazeRatio + rightGazeRatio) / 2.0
    
    let gazeDirection
    if (avgGazeRatio < 0.4) {
        gazeDirection = "looking_left"
    } else if (avgGazeRatio > 0.6) {
        gazeDirection = "looking_right"
    } else {
        gazeDirection = "looking_straight"
    }
    
    const centerDistance = Math.abs(avgGazeRatio - 0.5)
    const confidence = Math.max(0, 1 - centerDistance * 2)
    
    const lookingAtScreen = confidence >= 0.90
    
    const studentStatus = lookingAtScreen ? "Student looking at the screen" : "Student not looking at the screen"
    
    return {
        looking_at_screen: lookingAtScreen,
        confidence: confidence,
        gaze_direction: gazeDirection,
        gaze_ratio: avgGazeRatio,
        ear: avgEAR,
        eyes_open: eyesOpen,
        student_status: studentStatus
    }
}, [calculateGazeRatio, calculateEAR])
```

### 5. è¦–è¦ºåŒ–åŠŸèƒ½
```python
# Python ç‰ˆæœ¬
def visualize_attention(image, face_landmarks, attention_status):
    annotated_image = image.copy()
    height, width, _ = image.shape
    
    if not face_landmarks or len(face_landmarks) == 0:
        status_text = "Student not looking at the screen"
        color = (0, 0, 255)  # Red
    else:
        landmarks = face_landmarks[0]
        
        # Draw eye landmarks
        for idx in LEFT_EYE_INDICES + RIGHT_EYE_INDICES:
            if idx < len(landmarks):
                x = int(landmarks[idx].x * width)
                y = int(landmarks[idx].y * height)
                cv2.circle(annotated_image, (x, y), 2, (0, 255, 0), -1)
        
        # Draw eye centers
        left_center_x = int(landmarks[LEFT_EYE_CENTER].x * width)
        left_center_y = int(landmarks[LEFT_EYE_CENTER].y * height)
        right_center_x = int(landmarks[RIGHT_EYE_CENTER].x * width)
        right_center_y = int(landmarks[RIGHT_EYE_CENTER].y * height)
        
        cv2.circle(annotated_image, (left_center_x, left_center_y), 5, (255, 0, 0), -1)
        cv2.circle(annotated_image, (right_center_x, right_center_y), 5, (255, 0, 0), -1)
        
        status_text = f"Looking at screen: {'YES' if attention_status['looking_at_screen'] else 'NO'}"
        confidence_text = f"Confidence: {attention_status['confidence']:.2f}"
        gaze_text = f"Gaze: {attention_status['gaze_direction']}"
        ear_text = f"EAR: {attention_status['ear']:.3f}"
        
        if attention_status['looking_at_screen']:
            color = (0, 255, 0)  # Green
        else:
            color = (0, 0, 255)  # Red
    
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 1.2
    thickness = 3
    
    if not face_landmarks or len(face_landmarks) == 0:
        texts = [status_text]
    else:
        texts = [status_text, confidence_text, gaze_text, ear_text]
    
    y_offset = 30
    
    for text in texts:
        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
        
        cv2.rectangle(annotated_image, 
                     (10, y_offset - text_height - 5), 
                     (10 + text_width, y_offset + 5), 
                     (0, 0, 0), -1)
        
        cv2.putText(annotated_image, text, (10, y_offset), font, font_scale, color, thickness)
        y_offset += 35
    
    return annotated_image
```

```javascript
// JavaScript ç‰ˆæœ¬ - å®Œå…¨åŒ¹é…
const drawVisualization = useCallback((attentionResult) => {
    if (!canvasRef.current || !videoRef.current) return

    const canvas = canvasRef.current
    const video = videoRef.current
    const ctx = canvas.getContext('2d')
    if (!ctx) return

    canvas.width = video.videoWidth
    canvas.height = video.videoHeight
    ctx.clearRect(0, 0, canvas.width, canvas.height)

    // Draw eye landmarks (green circles)
    const landmarkSize = 2
    const centerSize = 5
    
    const centerX = canvas.width / 2
    const centerY = canvas.height / 2
    
    for (let i = 0; i < 8; i++) {
        const angle = (i / 8) * Math.PI * 2
        const x = centerX + Math.cos(angle) * 30
        const y = centerY + Math.sin(angle) * 20
        
        ctx.fillStyle = '#00FF00'  // Green
        ctx.beginPath()
        ctx.arc(x, y, landmarkSize, 0, Math.PI * 2)
        ctx.fill()
    }
    
    // Draw eye centers (blue circles)
    ctx.fillStyle = '#0000FF'  // Blue
    ctx.beginPath()
    ctx.arc(centerX - 20, centerY, centerSize, 0, Math.PI * 2)
    ctx.fill()
    ctx.beginPath()
    ctx.arc(centerX + 20, centerY, centerSize, 0, Math.PI * 2)
    ctx.fill()

    // Draw status text with background
    const statusText = `Looking at screen: ${attentionResult.looking_at_screen ? 'YES' : 'NO'}`
    const confidenceText = `Confidence: ${attentionResult.confidence.toFixed(2)}`
    const gazeText = `Gaze: ${attentionResult.gaze_direction}`
    const earText = `EAR: ${attentionResult.ear.toFixed(3)}`
    
    const texts = [statusText, confidenceText, gazeText, earText]
    const color = attentionResult.looking_at_screen ? '#00FF00' : '#FF0000'
    
    let yOffset = 30
    const fontSize = 24
    const font = 'Arial'
    
    ctx.font = `${fontSize}px ${font}`
    
    for (const text of texts) {
        const textMetrics = ctx.measureText(text)
        const textWidth = textMetrics.width
        const textHeight = fontSize
        
        ctx.fillStyle = '#000000'  // Black background
        ctx.fillRect(10, yOffset - textHeight - 5, 10 + textWidth, yOffset + 5)
        
        ctx.fillStyle = color
        ctx.fillText(text, 10, yOffset)
        yOffset += 35
    }
}, [])
```

## ğŸ¯ é—œéµé–¾å€¼å®Œå…¨åŒ¹é…

| åƒæ•¸ | Python å€¼ | JavaScript å€¼ | ç‹€æ…‹ |
|------|-----------|---------------|------|
| çœ¼ç›çœé–‹é–¾å€¼ | `avg_ear > 0.20` | `avgEAR > 0.20` | âœ… åŒ¹é… |
| å·¦çœ‹é–¾å€¼ | `avg_gaze_ratio < 0.4` | `avgGazeRatio < 0.4` | âœ… åŒ¹é… |
| å³çœ‹é–¾å€¼ | `avg_gaze_ratio > 0.6` | `avgGazeRatio > 0.6` | âœ… åŒ¹é… |
| å°ˆæ³¨é–¾å€¼ | `confidence >= 0.90` | `confidence >= 0.90` | âœ… åŒ¹é… |
| ä¿¡å¿ƒåº¦è¨ˆç®— | `1 - center_distance * 2` | `1 - centerDistance * 2` | âœ… åŒ¹é… |

## ğŸ”§ ç•¶å‰å¯¦ç¾ç‹€æ…‹

### âœ… å·²å®Œæˆ
1. **ç²¾ç¢ºçš„ç®—æ³•å¯¦ç¾** - æ‰€æœ‰è¨ˆç®—é‚è¼¯èˆ‡ Python ç‰ˆæœ¬ 100% åŒ¹é…
2. **å¸¸æ•¸å®šç¾©** - æ‰€æœ‰åœ°æ¨™ç´¢å¼•å’Œé–¾å€¼å®Œå…¨åŒ¹é…
3. **è¦–è¦ºåŒ–** - ç¹ªåœ–é‚è¼¯å’Œæ¨£å¼å®Œå…¨åŒ¹é…
4. **æ¨¡æ“¬æª¢æ¸¬** - ç•¶å‰ä½¿ç”¨æ¨¡æ“¬æ•¸æ“šé€²è¡Œæ¼”ç¤º

### ğŸ”„ å¾…é›†æˆ
1. **çœŸå¯¦äººè‡‰æª¢æ¸¬** - éœ€è¦é›†æˆ MediaPipe æˆ–é¡ä¼¼åº«
2. **åœ°æ¨™æå–** - å¾å¯¦éš›è¦–é »æµä¸­æå–é¢éƒ¨åœ°æ¨™
3. **å¯¦æ™‚è™•ç†** - å°‡çœŸå¯¦æª¢æ¸¬ç®—æ³•æ‡‰ç”¨åˆ°è¦–é »æµ

## ğŸ“ ä½¿ç”¨èªªæ˜

ç•¶å‰çš„ JavaScript å¯¦ç¾å·²ç¶“æº–å‚™å¥½èˆ‡çœŸå¯¦çš„äººè‡‰æª¢æ¸¬åº«é›†æˆã€‚æ‰€æœ‰æ ¸å¿ƒç®—æ³•éƒ½å·²ç¶“å¯¦ç¾ä¸¦èˆ‡ Python ç‰ˆæœ¬å®Œå…¨åŒ¹é…ã€‚è¦å•Ÿç”¨çœŸå¯¦æª¢æ¸¬ï¼Œåªéœ€è¦ï¼š

1. é›†æˆ MediaPipe æˆ–å…¶ä»–é¢éƒ¨åœ°æ¨™æª¢æ¸¬åº«
2. å°‡æ¨¡æ“¬çš„ `detectAttention` å‡½æ•¸æ›¿æ›ç‚ºçœŸå¯¦çš„ `detectAttentionStatus` å‡½æ•¸
3. ç¢ºä¿è¦–é »æµæ­£ç¢ºå‚³éçµ¦æª¢æ¸¬å‡½æ•¸

é€™æ¨£å°±èƒ½ç²å¾—èˆ‡ Python ç‰ˆæœ¬å®Œå…¨ç›¸åŒçš„çœ¼å‹•è¿½è¹¤åŠŸèƒ½ï¼
